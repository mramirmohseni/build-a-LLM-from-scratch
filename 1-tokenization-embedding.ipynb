{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMp0nayPt6kcpmQhk1VWV5y"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import torch\n","import tiktoken"],"metadata":{"id":"4X2YmSKEHaxe","executionInfo":{"status":"ok","timestamp":1750940558300,"user_tz":-210,"elapsed":9,"user":{"displayName":"Amir Mohseni","userId":"02502065642708542298"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["- As the first step, raw text should brake into tokens, which can be words or characters.\n","- Then, the tokens are converted into integer representations, termed token IDs."],"metadata":{"id":"Yp38C2adVpOx"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"HaeETnt-boC7","outputId":"0471e328-dd2e-4d1b-d234-4d85426cae32"},"outputs":[{"name":"stdout","output_type":"stream","text":["total number of characters:  20479\n","I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"]}],"source":["with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n","    raw_text = f.read()\n","print(\"total number of characters: \", len(raw_text))\n","print(raw_text[:99])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EAQqOXbgboDA","outputId":"0a79a3ba-3da5-4b0c-8bd8-c6a2d2c39d4b"},"outputs":[{"name":"stdout","output_type":"stream","text":["4649\n","['I', 'HAD', 'always', 'thought', 'Jack', 'Gisburn', 'rather', 'a', 'cheap', 'genius', '--', 'though', 'a', 'good', 'fellow', 'enough', '--', 'so', 'it', 'was', 'no', 'great', 'surprise', 'to', 'me', 'to', 'hear', 'that', ',', 'in']\n"]}],"source":["import re\n","preprocessed = re.split(r'([,.?_!\"()\\']|--|\\s)', raw_text)\n","preprocessed = [item.strip() for item in preprocessed if item.strip()]\n","print(len(preprocessed))\n","print(preprocessed[:30])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ui1qqZUkboDB","outputId":"273b22ab-5642-4606-e2ed-0df605760775"},"outputs":[{"name":"stdout","output_type":"stream","text":["1159\n"]}],"source":["all_words = sorted(list(set(preprocessed)))\n","vocab_size = len(all_words)\n","print(vocab_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2tSDNokuboDC","outputId":"05092bbe-f38c-4810-869e-0ee58ff366da"},"outputs":[{"name":"stdout","output_type":"stream","text":["('!', 0)\n","('\"', 1)\n","(\"'\", 2)\n","('(', 3)\n","(')', 4)\n","(',', 5)\n","('--', 6)\n","('.', 7)\n","(':', 8)\n","(';', 9)\n","('?', 10)\n","('A', 11)\n","('Ah', 12)\n","('Among', 13)\n","('And', 14)\n","('Are', 15)\n","('Arrt', 16)\n","('As', 17)\n","('At', 18)\n","('Be', 19)\n","('Begin', 20)\n","('Burlington', 21)\n","('But', 22)\n","('By', 23)\n","('Carlo', 24)\n","('Carlo;', 25)\n","('Chicago', 26)\n","('Claude', 27)\n","('Come', 28)\n","('Croft', 29)\n","('Destroyed', 30)\n","('Devonshire', 31)\n","('Don', 32)\n","('Dubarry', 33)\n","('Emperors', 34)\n","('Florence', 35)\n","('For', 36)\n","('Gallery', 37)\n","('Gideon', 38)\n","('Gisburn', 39)\n","('Gisburns', 40)\n","('Grafton', 41)\n","('Greek', 42)\n","('Grindle', 43)\n","('Grindle:', 44)\n","('Grindles', 45)\n","('HAD', 46)\n","('Had', 47)\n","('Hang', 48)\n","('Has', 49)\n","('He', 50)\n","('Her', 51)\n"]}],"source":["vocab = {token:integer for integer, token in enumerate(all_words)}\n","for i, item in enumerate(vocab.items()):\n","    print(item)\n","    if i > 50:\n","        break"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5EoDNGE3boDC"},"outputs":[],"source":["class SimpleTokenizerV1:\n","    def __init__(self, vocab) -> None:\n","        self.str_to_int = vocab\n","        self.int_to_str = {integer: token for token, integer in vocab.items()}\n","\n","    def encode(self, text):\n","        preprocessed = re.split(r'([,.?_!\"()\\']|--|\\s)', text)\n","        preprocessed = [item.strip() for item in preprocessed if item.strip()]\n","        ids = [self.str_to_int[t] for t in preprocessed]\n","        return ids\n","\n","    def decode(self, ids):\n","        text = \" \".join([self.int_to_str[id] for id in ids])\n","        text = re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text)\n","        return text"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PvHdU5bCboDD","outputId":"3bf71b94-c660-4429-9ae0-b4065b338ef3"},"outputs":[{"name":"stdout","output_type":"stream","text":["[91, 837, 547, 423, 1136, 119, 558, 738, 510, 986, 7]\n"]}],"source":["tokenizer = SimpleTokenizerV1(vocab)\n","text = \"She raised her eyebrows with a hint of good-humoured surprise.\"\n","ids = tokenizer.encode(text)\n","print(ids)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B4rCQu8lboDF","outputId":"3135c12e-a7b9-4d73-e0e0-fe0970a3b92b"},"outputs":[{"name":"stdout","output_type":"stream","text":["She raised her eyebrows with a hint of good-humoured surprise.\n"]}],"source":["print(tokenizer.decode(ids))"]},{"cell_type":"markdown","metadata":{"id":"QtKS_ZxRboDG"},"source":["### =====================\n","- Special tokens, such as <|unk|> and <|endoftext|>, can be added to enhance the model's understanding and handle various contexts, such as unknown words or marking the boundary between unrelated texts."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9Xmo1h_2boDH","outputId":"f092bc07-09f3-40fb-b3e3-47cea06f2175"},"outputs":[{"name":"stdout","output_type":"stream","text":["1161\n"]}],"source":["all_tokens = sorted(list(set(preprocessed)))\n","all_tokens.extend([\"<|endoftext|>\", \"<|unk|>\"])\n","vocab = {token: integer for integer, token in enumerate(all_tokens)}\n","print(len(vocab))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6bE8IxiWboDI"},"outputs":[],"source":["class SimpleTokenizerV2:\n","    def __init__(self, vocab) -> None:\n","        self.str_to_int = vocab\n","        self.int_to_str = {integer: token for token, integer in vocab.items()}\n","\n","    def encode(self, text):\n","        preprocessed = re.split(r'([,.?_!\"()\\']|--|\\s)', text)\n","        preprocessed = [item.strip() for item in preprocessed if item.strip()]\n","        preprocessed = [token if token in self.str_to_int else \"<|unk|>\" for token in preprocessed]\n","        ids = [self.str_to_int[t] for t in preprocessed]\n","        return ids\n","\n","    def decode(self, ids):\n","        text = \" \".join([self.int_to_str[id] for id in ids])\n","        text = re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text)\n","        return text"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vpbUa-G8boDJ","outputId":"d6b268c2-c0e1-4ee5-f5b5-11ee813afd19"},"outputs":[{"name":"stdout","output_type":"stream","text":["[114, 904, 1155, 1160, 161, 1160, 10]\n"]}],"source":["tokenizer = SimpleTokenizerV2(vocab)\n","text  = \"When should you build an agent?\"\n","ids = tokenizer.encode(text)\n","print(ids)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5iLCavAhboDP","outputId":"50208dcf-303b-4f2b-f6f6-58dc3ee291fe"},"outputs":[{"name":"stdout","output_type":"stream","text":["When should you <|unk|> an <|unk|>?\n"]}],"source":["print(tokenizer.decode(ids))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zBYLUa6MboDQ","outputId":"c096928e-6f8c-4b0f-d89a-cc1e7226790f"},"outputs":[{"name":"stdout","output_type":"stream","text":["[57, 598, 702, 1160, 472, 5, 161, 1160, 1160, 738, 1030, 1160, 1160, 1159, 1160, 1116, 1024, 1160, 642, 579, 1160, 1117, 1160, 1160]\n"]}],"source":["tokenizer = SimpleTokenizerV2(vocab)\n","text1  = \"In its most fundamental form, an agent consists of three core components:\"\n","text2 = \"Hereâ€™s what this looks like in code when using OpenAI\"\n","text = \" <|endoftext|> \".join((text1,text2))\n","ids = tokenizer.encode(text)\n","print(ids)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EPFrJfRiboDR","outputId":"e43671fd-744d-46f8-f651-2646237eefd5"},"outputs":[{"name":"stdout","output_type":"stream","text":["In its most <|unk|> form, an <|unk|> <|unk|> of three <|unk|> <|unk|> <|endoftext|> <|unk|> what this <|unk|> like in <|unk|> when <|unk|> <|unk|>\n"]}],"source":["print(tokenizer.decode(ids))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sY9yvbyhboDR","outputId":"58e7f6df-8325-4234-e2a6-28c00be40b33"},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mRunning cells with '.venv (Python 3.13.4)' requires the ipykernel package.\n","\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n","\u001b[1;31mCommand: '/Users/amir/Documents/src/build-llm/.venv/bin/python -m pip install ipykernel -U --force-reinstall'"]}],"source":["import tiktoken"]},{"cell_type":"markdown","source":["- The byte pair encoding (BPE) tokenizer used for LLMs like GPT-2 and GPT-3 can efficiently handle unknown words by breaking them down into subword units or individual characters."],"metadata":{"id":"XuN_NKwbbuBg"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"CAq8HteTboDR"},"outputs":[],"source":["import tiktoken\n","from importlib.metadata import version\n","print(\"tiktoken version:\", version(\"tiktoken\"))"]},{"cell_type":"code","source":["tokenizer = tiktoken.get_encoding(\"gpt2\")"],"metadata":{"id":"WIs_luu8b1hT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["text = (\n","    \"Hello, do you like tea? <|endoftext|> In the sunlit terraces\"\n","     \" of someunknownPlace.\"\n",")\n","integers = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n","print(integers)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oflhx-_IMXMA","executionInfo":{"status":"ok","timestamp":1750639421167,"user_tz":-210,"elapsed":21,"user":{"displayName":"Amir Mohseni","userId":"02502065642708542298"}},"outputId":"5f306ea1-80b5-48cc-d411-5ce7f3db3d2f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[15496, 11, 466, 345, 588, 8887, 30, 220, 50256, 554, 262, 4252, 18250, 8812, 2114, 286, 617, 34680, 27271, 13]\n"]}]},{"cell_type":"code","source":["tokenizer.decode(integers)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"tMZ9oaBxMv_k","executionInfo":{"status":"ok","timestamp":1750639423318,"user_tz":-210,"elapsed":222,"user":{"displayName":"Amir Mohseni","userId":"02502065642708542298"}},"outputId":"a16a34cb-ad0b-4b3a-8f45-897feba604cc"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Hello, do you like tea? <|endoftext|> In the sunlit terraces of someunknownPlace.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","source":["- We use a sliding window approach on tokenized data to generate input- target pairs for LLM training."],"metadata":{"id":"_HOj68NfWN_G"}},{"cell_type":"code","source":["with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n","  raw_text = f.read()\n","\n","enc_text = tokenizer.encode(raw_text)\n","print(len(enc_text))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZEqUXGcaPT3h","executionInfo":{"status":"ok","timestamp":1750639717553,"user_tz":-210,"elapsed":10,"user":{"displayName":"Amir Mohseni","userId":"02502065642708542298"}},"outputId":"99c7ffc8-e501-4842-b9a6-425e2f257497"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["5145\n"]}]},{"cell_type":"code","source":["enc_sample = enc_text[50:]\n","context_size = 4\n","x = enc_sample[:context_size]\n","y = enc_sample[1:context_size+1]\n","print(f\"x: {x}\")\n","print(f\"y:      {y}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5aH_-4o4Q9W3","executionInfo":{"status":"ok","timestamp":1750639939537,"user_tz":-210,"elapsed":7,"user":{"displayName":"Amir Mohseni","userId":"02502065642708542298"}},"outputId":"cfb99ca9-2656-483a-b08a-05ca774498e8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["x: [290, 4920, 2241, 287]\n","y:      [4920, 2241, 287, 257]\n"]}]},{"cell_type":"code","source":["import torch\n","from torch.utils.data import Dataset, DataLoader"],"metadata":{"id":"i9s9EBNPTiSv","executionInfo":{"status":"ok","timestamp":1750940442683,"user_tz":-210,"elapsed":12,"user":{"displayName":"Amir Mohseni","userId":"02502065642708542298"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["class GPTDatasetV1(Dataset):\n","  def __init__(self, text, tokenizer, max_length, stride):\n","    self.tokenizer = tokenizer\n","    self.input_ids = []\n","    self.target_ids = []\n","\n","    token_ids = tokenizer.encode(text)\n","\n","    for i in range(0, len(token_ids) - max_length, stride):\n","      input_chunk = token_ids[i:i+max_length]\n","      target_chunk = token_ids[i+1:i+max_length+1]\n","      self.input_ids.append(torch.tensor(input_chunk))\n","      self.target_ids.append(torch.tensor(target_chunk))\n","\n","  def __getitem__(self, idx):\n","    return self.input_ids[idx], self.target_ids[idx]\n","\n","  def __len__(self):\n","    return len(self.input_ids)"],"metadata":{"id":"yVVrc3hlRHdI","executionInfo":{"status":"ok","timestamp":1750940442683,"user_tz":-210,"elapsed":10,"user":{"displayName":"Amir Mohseni","userId":"02502065642708542298"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["def create_dataloader_v1(text,\n","                         batch_size=4,\n","                         max_length=256,\n","                         stride=128,\n","                         shuffle=True,\n","                         drop_last=True,\n","                         num_workers=0):\n","  tokenizer = tiktoken.get_encoding(\"gpt2\")\n","  dataset = GPTDatasetV1(text, tokenizer, max_length, stride)\n","  dataloader = DataLoader(dataset,\n","                          batch_size=batch_size,\n","                          shuffle=shuffle,\n","                          drop_last=drop_last,\n","                          num_workers=num_workers)\n","  return dataloader\n","\n"],"metadata":{"id":"ErosywPsVrz9","executionInfo":{"status":"ok","timestamp":1750940445492,"user_tz":-210,"elapsed":3,"user":{"displayName":"Amir Mohseni","userId":"02502065642708542298"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n","  raw_text = f.read()\n","\n","dataloader = create_dataloader_v1(raw_text, batch_size=1, max_length=4, stride=1, shuffle=False)\n","data_iter = iter(dataloader)\n","first_batch = next(data_iter)\n","print(first_batch)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oOQg0r5SXaZe","executionInfo":{"status":"ok","timestamp":1750940566448,"user_tz":-210,"elapsed":2561,"user":{"displayName":"Amir Mohseni","userId":"02502065642708542298"}},"outputId":"d3f1d338-4e4f-445f-96cb-a622cbd66907"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["[tensor([[  40,  367, 2885, 1464]]), tensor([[ 367, 2885, 1464, 1807]])]\n"]}]},{"cell_type":"code","source":["second_batch = next(data_iter)\n","print(second_batch)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v8sILRE1YAHz","executionInfo":{"status":"ok","timestamp":1750641706925,"user_tz":-210,"elapsed":23,"user":{"displayName":"Amir Mohseni","userId":"02502065642708542298"}},"outputId":"b783848b-62a9-46f1-b811-bf993578d18b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[tensor([[ 367, 2885, 1464, 1807]]), tensor([[2885, 1464, 1807, 3619]])]\n"]}]},{"cell_type":"markdown","source":["### Embedding"],"metadata":{"id":"V5gL13DuGV6x"}},{"cell_type":"markdown","source":["- tokenizing text -> convert tokens to token IDs -> embedding vectors\n","<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch02_compressed/15.webp\" width=\"400px\">\n","\n","- initialize embedding weights with random values\n","- train embedding weights with backpropagation in future (the values will optimized during LLM training)"],"metadata":{"id":"Z-motkjnEv3O"}},{"cell_type":"markdown","source":["for example we have vocab_size = 6, embedding_size = 6"],"metadata":{"id":"-qZFtur2FP6q"}},{"cell_type":"code","source":["vocab_size = 6\n","output_dim = 3"],"metadata":{"id":"rAL4sUxnHNyT","executionInfo":{"status":"ok","timestamp":1750821844325,"user_tz":-210,"elapsed":7,"user":{"displayName":"Amir Mohseni","userId":"02502065642708542298"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["torch.manual_seed(123)\n","embedding_layer = torch.nn.Embedding(vocab_size, output_dim)\n","print(embedding_layer)\n","print(embedding_layer.weight)\n","print(\"third word in vocab has embedding weight of: \\n\")\n","print(embedding_layer(torch.tensor([2])))\n","print(\"===========================================================================\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ElSvPH5sHTC6","executionInfo":{"status":"ok","timestamp":1750822222552,"user_tz":-210,"elapsed":5,"user":{"displayName":"Amir Mohseni","userId":"02502065642708542298"}},"outputId":"64f24145-9204-4a64-d116-d8006f111e28"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Embedding(6, 3)\n","Parameter containing:\n","tensor([[ 0.3374, -0.1778, -0.1690],\n","        [ 0.9178,  1.5810,  1.3010],\n","        [ 1.2753, -0.2010, -0.1606],\n","        [-0.4015,  0.9666, -1.1481],\n","        [-1.1589,  0.3255, -0.6315],\n","        [-2.8400, -0.7849, -1.4096]], requires_grad=True)\n","third word in vocab has embedding weight of: \n","\n","tensor([[ 1.2753, -0.2010, -0.1606]], grad_fn=<EmbeddingBackward0>)\n","===========================================================================\n"]}]},{"cell_type":"code","source":["input_ids = torch.tensor([2, 3, 5, 1])\n","print(embedding_layer(input_ids))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Whj_WZCYIlnc","executionInfo":{"status":"ok","timestamp":1750822435437,"user_tz":-210,"elapsed":10,"user":{"displayName":"Amir Mohseni","userId":"02502065642708542298"}},"outputId":"27a0908a-5860-49f7-9ae6-58cee15a8b4d"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 1.2753, -0.2010, -0.1606],\n","        [-0.4015,  0.9666, -1.1481],\n","        [-2.8400, -0.7849, -1.4096],\n","        [ 0.9178,  1.5810,  1.3010]], grad_fn=<EmbeddingBackward0>)\n"]}]},{"cell_type":"markdown","source":["- Embedding layer is look-up operation that retreive rows from embedding layer's weight matrix via token ID\n","- Embedding layer is just a more efficient implementation equivalent to the one-hot encoding and matrix-multiplication approach, it can be seen as a neural network layer that can be optimized via backpropagation.\n"],"metadata":{"id":"RD2n7nUPHpyV"}},{"cell_type":"markdown","source":["#### Encode positional information"],"metadata":{"id":"KjWRyXgpKNLl"}},{"cell_type":"markdown","source":["- A minor shortcoming of LLMs is that their self- attention mechanism, which will be covered later, doesn't have a notion of position or order for the tokens within a sequence.\n","- The way the previously introduced embedding layer works is that the same token ID always gets mapped to the same vector representation, regardless of where the token ID is positioned in the input sequence\n","\n","There are two categories of position-aware embedding:\n","- Relative positional embedding\n","- Absolute positional embedding\n","\n","Absolute positional embedding:\n","- For each position in the input sequence, a unique embedding is added to the token's embedding to convey its exact location\n","\n","Relative positional embedding\n","- the emphasis of relative positional embeddings is on the relative position or distance between tokens. This means the model learns the relationships in terms of \"how far apart\" rather than \"at which exact position.\"\n","- The advantage here is that the model can generalize better to sequences of varying lengths, even if it hasn't seen such lengths during training.\n","\n","The choice between them often depends on the specific application and the nature of the data being processed.\n","\n","OpenAI's GPT models use absolute positional embeddings that are optimized during the training process rather than being fixed or predefined like the positional encodings in the original Transformer model.\n","\n","Positional embeddings are added to the token embedding vector to create the input embeddings for an LLM (The positional vectors have the same dimension as the original token embeddings).\n","\n","<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch02_compressed/18.webp\" width=\"500px\">"],"metadata":{"id":"q7i4cSiOJjZL"}},{"cell_type":"markdown","source":["in GPT-3, the embedding size is 12,288 dimensions (but we take it as 256)\n","also, vocab_size = 50,257"],"metadata":{"id":"hlF-oPrPKNI0"}},{"cell_type":"code","source":["vocab_size = 50257\n","output_dim = 256\n","token_embedding_layer = torch.nn.Embedding(vocab_size, output_dim)"],"metadata":{"id":"chXDmnWRKGLB","executionInfo":{"status":"ok","timestamp":1750940457152,"user_tz":-210,"elapsed":367,"user":{"displayName":"Amir Mohseni","userId":"02502065642708542298"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["max_length = 4\n","dataloader = create_dataloader_v1(\n","    raw_text, batch_size=8, max_length=max_length,\n","    stride=max_length, shuffle=False)\n","data_iter = iter(dataloader)\n","inputs, targets = next(data_iter)\n","print(\"Token IDs:\\n\", inputs)\n","print(\"\\nInputs shape:\\n\", inputs.shape)\n","token_embeddings = token_embedding_layer(inputs)\n","print(\"\\nToken Embedding shape:\\n\", token_embeddings.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PS1AiGf1KNs4","executionInfo":{"status":"ok","timestamp":1750940894715,"user_tz":-210,"elapsed":361,"user":{"displayName":"Amir Mohseni","userId":"02502065642708542298"}},"outputId":"a81fa9f9-eb77-4fa6-9d56-d2479a79d0dd"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Token IDs:\n"," tensor([[   40,   367,  2885,  1464],\n","        [ 1807,  3619,   402,   271],\n","        [10899,  2138,   257,  7026],\n","        [15632,   438,  2016,   257],\n","        [  922,  5891,  1576,   438],\n","        [  568,   340,   373,   645],\n","        [ 1049,  5975,   284,   502],\n","        [  284,  3285,   326,    11]])\n","\n","Inputs shape:\n"," torch.Size([8, 4])\n","\n","Token Embedding shape:\n"," torch.Size([8, 4, 256])\n"]}]},{"cell_type":"markdown","source":["- the data batch consists of 8 text samples with 4 tokens each has vector embeddings of 256\n","\n","- For a GPT model's absolute embedding approach, we just need to create another embedding layer that has the same dimension as the token_embedding_layer"],"metadata":{"id":"m5dnmgepORc9"}},{"cell_type":"code","source":["context_length = max_length\n","pos_embedding_layer = torch.nn.Embedding(context_length, output_dim)\n","pos_embeddings = pos_embedding_layer(torch.arange(context_length))\n","# torch.arange(context_length) is equal to tensor([0, 1, 2, 3])\n","print(pos_embeddings.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YXao23UUM63w","executionInfo":{"status":"ok","timestamp":1750941075333,"user_tz":-210,"elapsed":375,"user":{"displayName":"Amir Mohseni","userId":"02502065642708542298"}},"outputId":"3b319633-377a-49cc-e016-e8976036f440"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([4, 256])\n"]}]},{"cell_type":"code","source":["# considering broadcasting rule in pytorch\n","input_embeddings = token_embeddings + pos_embeddings\n","print(input_embeddings.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GkVDzM2AQZAj","executionInfo":{"status":"ok","timestamp":1750941714279,"user_tz":-210,"elapsed":416,"user":{"displayName":"Amir Mohseni","userId":"02502065642708542298"}},"outputId":"25b810b0-5e0a-4f93-ea8f-186e4d2b3e5a"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([8, 4, 256])\n"]}]},{"cell_type":"markdown","source":["<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch02_compressed/19.webp\" width=\"400px\">"],"metadata":{"id":"-BQoQ43MS9t1"}}]}